# OpenCode CI/CD Integration Guide

## Table of Contents
1. [Overview](#overview)
2. [Prerequisites](#prerequisites)
3. [Security Considerations](#security-considerations)
4. [GitHub Actions Examples](#github-actions-examples)
5. [GitLab CI Examples](#gitlab-ci-examples)
6. [Jenkins Pipeline Examples](#jenkins-pipeline-examples)
7. [Shell Script Patterns](#shell-script-patterns)
8. [Docker Integration](#docker-integration)
9. [Error Handling & Logging](#error-handling--logging)
10. [Best Practices](#best-practices)
11. [Troubleshooting](#troubleshooting)

## Overview

This guide demonstrates how to integrate OpenCode into CI/CD pipelines for automated code review, feature implementation, documentation generation, and development assistance using the `opencode run` command and various agents.

## Prerequisites

### Installation in CI Environment
```bash
# Using the install script
curl -fsSL https://opencode.ai/install | bash

# Or using npm
npm install -g opencode-ai

# Or using Docker
docker pull ghcr.io/anomalyco/opencode
```

### Environment Setup
```bash
# Set up provider API keys
export OPENAI_API_KEY="your-openai-key"
export ANTHROPIC_API_KEY="your-anthropic-key"
# Or use OpenCode Zen
export OPENCODE_ZEN_API_KEY="your-zen-key"

# Optional: Disable interactive features
export OPENCODE_DISABLE_TERMINAL_TITLE=true
export OPENCODE_DISABLE_AUTOUPDATE=true
```

## Security Considerations

### Agent Selection by Environment

#### Development Environment
```bash
# Full capability agent for development
opencode run --agent build "Implement the new authentication feature"
```

#### Staging Environment  
```bash
# Analysis-focused agent for validation
opencode run --agent plan "Analyze the deployment configuration for issues"
```

#### Production CI/CD
```bash
# Read-only exploration for security
opencode run --agent explore "Check for security vulnerabilities in the codebase"
```

### Sensitive Data Protection
```bash
# Never include credentials in prompts
# Use environment variables for dynamic content
SANITIZED_ERROR=$(echo "$ERROR" | sed 's/password=[^&]*/password=****/g')
opencode run --agent general "Analyze this sanitized error: $SANITIZED_ERROR"
```

## GitHub Actions Examples

### Example 1: AI-Powered Code Review on Pull Requests
```yaml
name: OpenCode AI Review
on:
  pull_request:
    types: [opened, synchronize]

jobs:
  ai-review:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install OpenCode
        run: |
          curl -fsSL https://opencode.ai/install | bash
          echo "$HOME/.local/bin" >> $GITHUB_PATH

      - name: Configure OpenCode
        run: |
          mkdir -p ~/.config/opencode
          echo '{"providers": {"anthropic": {"apiKey": "${{ secrets.ANTHROPIC_API_KEY }}"}}}' > ~/.config/opencode/opencode.json
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}

      - name: Get changed files
        id: changed-files
        run: |
          git diff --name-only ${{ github.event.pull_request.base.sha }} ${{ github.sha }} > changed_files.txt
          echo "files=$(cat changed_files.txt | tr '\n' ' ')" >> $GITHUB_OUTPUT

      - name: AI Code Review
        run: |
          REVIEW_RESULT=$(opencode run --agent plan --format json \
            "Review the following changed files for security issues, performance problems, and code quality. Files: ${{ steps.changed-files.outputs.files }}" \
            | jq -r '.content // .message // .')
          
          # Save review to file for comment
          cat << 'EOF' > review_comment.md
          ## ü§ñ OpenCode AI Review Results
          
          $REVIEW_RESULT
          
          ---
          *Generated by OpenCode AI Agent: plan*
          EOF

      - name: Comment PR
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const reviewComment = fs.readFileSync('review_comment.md', 'utf8');
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: reviewComment
            });
```

### Example 2: Automated Feature Implementation
```yaml
name: AI Feature Development
on:
  issues:
    types: [labeled]

jobs:
  implement-feature:
    runs-on: ubuntu-latest
    if: contains(github.event.label.name, 'ai-implement')
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install OpenCode
        run: |
          curl -fsSL https://opencode.ai/install | bash
          echo "$HOME/.local/bin" >> $GITHUB_PATH

      - name: Configure OpenCode  
        run: |
          mkdir -p ~/.config/opencode
          echo '{"providers": {"opencode": {"apiKey": "${{ secrets.OPENCODE_ZEN_API_KEY }}"}}}' > ~/.config/opencode/opencode.json
        env:
          OPENCODE_ZEN_API_KEY: ${{ secrets.OPENCODE_ZEN_API_KEY }}

      - name: Extract issue requirements
        id: requirements
        run: |
          ISSUE_BODY="${{ github.event.issue.body }}"
          ISSUE_TITLE="${{ github.event.issue.title }}"
          echo "title=$ISSUE_TITLE" >> $GITHUB_OUTPUT
          echo "requirements<<EOF" >> $GITHUB_OUTPUT
          echo "$ISSUE_BODY" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Plan implementation
        run: |
          opencode run --agent plan --title "Plan: ${{ steps.requirements.outputs.title }}" \
            "Create a detailed implementation plan for this feature request: 
             
             Title: ${{ steps.requirements.outputs.title }}
             
             Requirements: ${{ steps.requirements.outputs.requirements }}
             
             Please analyze the existing codebase and create a step-by-step implementation plan."

      - name: Implement feature
        run: |
          opencode run --agent build --continue --title "Implement: ${{ steps.requirements.outputs.title }}" \
            "Now implement the feature based on the plan. Create all necessary files, update existing code, and add appropriate tests."

      - name: Create pull request
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "OpenCode AI"
          
          # Create feature branch
          BRANCH_NAME="feature/ai-implement-${{ github.event.issue.number }}"
          git checkout -b "$BRANCH_NAME"
          
          # Commit changes
          git add .
          git commit -m "AI Implementation: ${{ steps.requirements.outputs.title }}

          Resolves #${{ github.event.issue.number }}
          
          This feature was implemented by OpenCode AI based on the requirements in the issue."
          
          git push origin "$BRANCH_NAME"
          
          # Create PR
          gh pr create \
            --title "AI Implementation: ${{ steps.requirements.outputs.title }}" \
            --body "This PR implements the feature requested in issue #${{ github.event.issue.number }}.

          **Implementation generated by OpenCode AI**
          
          Please review the changes and test thoroughly before merging.
          
          Closes #${{ github.event.issue.number }}" \
            --base main \
            --head "$BRANCH_NAME"
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
```

### Example 3: Test Failure Analysis and Auto-Fix
```yaml
name: AI Test Analysis
on:
  workflow_run:
    workflows: ["Tests"]
    types: [completed]

jobs:
  analyze-failures:
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'failure' }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install OpenCode
        run: |
          curl -fsSL https://opencode.ai/install | bash
          echo "$HOME/.local/bin" >> $GITHUB_PATH

      - name: Configure OpenCode
        run: |
          mkdir -p ~/.config/opencode
          echo '{"providers": {"anthropic": {"apiKey": "${{ secrets.ANTHROPIC_API_KEY }}"}}}' > ~/.config/opencode/opencode.json
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}

      - name: Download test artifacts
        uses: actions/download-artifact@v3
        with:
          name: test-results
          run-id: ${{ github.event.workflow_run.id }}

      - name: Analyze and fix test failures
        run: |
          if [ -f "test_output.log" ]; then
            # First analyze the failures
            ANALYSIS=$(opencode run --agent general --title "Test Failure Analysis" \
              "Analyze these test failures and suggest fixes. Include the specific files that need to be changed and what changes to make." \
              --file test_output.log)
            
            echo "## Test Failure Analysis" > analysis_report.md
            echo "$ANALYSIS" >> analysis_report.md
            
            # Attempt to implement fixes
            AUTO_FIX=$(opencode run --agent build --continue --title "Auto-fix Test Failures" \
              "Based on the previous analysis, implement the suggested fixes to resolve the test failures. Make minimal, targeted changes.")
            
            echo "" >> analysis_report.md
            echo "## Auto-Fix Implementation" >> analysis_report.md
            echo "$AUTO_FIX" >> analysis_report.md
          fi

      - name: Create fix PR if changes made
        run: |
          if [ -n "$(git status --porcelain)" ]; then
            git config --local user.email "action@github.com"
            git config --local user.name "OpenCode AI"
            
            BRANCH_NAME="fix/ai-test-failures-$(date +%s)"
            git checkout -b "$BRANCH_NAME"
            git add .
            git commit -m "AI Auto-fix: Resolve test failures

            Automatically generated fixes for test failures detected in workflow run ${{ github.event.workflow_run.id }}"
            
            git push origin "$BRANCH_NAME"
            
            gh pr create \
              --title "ü§ñ AI Auto-fix: Resolve Test Failures" \
              --body-file analysis_report.md \
              --label "automated,bug-fix" \
              --base main \
              --head "$BRANCH_NAME"
          else
            # Just create an issue with analysis if no fixes were made
            gh issue create \
              --title "Test Failures Need Manual Review - $(date)" \
              --body-file analysis_report.md \
              --label "bug,needs-review"
          fi
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
```

## GitLab CI Examples

### Example 1: Security Audit Pipeline
```yaml
# .gitlab-ci.yml
stages:
  - security-audit
  - documentation
  - quality-gate

variables:
  OPENCODE_DISABLE_AUTOUPDATE: "true"
  OPENCODE_DISABLE_TERMINAL_TITLE: "true"

security-audit:
  stage: security-audit
  image: node:18
  before_script:
    - npm install -g opencode-ai
    - mkdir -p ~/.config/opencode
    - echo "{\"providers\":{\"anthropic\":{\"apiKey\":\"$ANTHROPIC_API_KEY\"}}}" > ~/.config/opencode/opencode.json
  script:
    - |
      # Security audit with plan agent (read-only analysis)
      AUDIT_RESULT=$(opencode run --agent plan --format json \
        "Perform a comprehensive security audit of this codebase. Focus on:
        - Authentication and authorization vulnerabilities
        - Input validation issues  
        - SQL injection risks
        - XSS vulnerabilities
        - Insecure dependencies
        - Configuration security
        Provide specific file locations and remediation steps." | jq -r '.content // .message // .')
      
      echo "# Security Audit Results" > security_audit.md
      echo "$AUDIT_RESULT" >> security_audit.md
      
      # Check for critical issues
      if echo "$AUDIT_RESULT" | grep -i "critical\|severe\|high.*risk\|vulnerability"; then
        echo "‚ö†Ô∏è Security issues found - see artifacts"
        exit 1
      fi
      
      echo "‚úÖ No critical security issues detected"
  artifacts:
    reports:
      junit: security_audit.md
    paths:
      - security_audit.md
    expire_in: 1 week
  only:
    - merge_requests
    - main

documentation-check:
  stage: documentation
  image: node:18
  before_script:
    - npm install -g opencode-ai
    - mkdir -p ~/.config/opencode
    - echo "{\"providers\":{\"opencode\":{\"apiKey\":\"$OPENCODE_ZEN_API_KEY\"}}}" > ~/.config/opencode/opencode.json
  script:
    - |
      # Check if documentation needs updates
      DOC_ANALYSIS=$(opencode run --agent explore \
        "Analyze the codebase and identify any missing or outdated documentation. 
         Check for:
         - API endpoints without documentation
         - Public functions without docstrings
         - README files that need updates
         - Missing installation/setup instructions")
      
      echo "$DOC_ANALYSIS" > doc_analysis.md
      
      # Auto-generate missing documentation
      if echo "$DOC_ANALYSIS" | grep -i "missing\|outdated\|needs.*update"; then
        opencode run --agent build --continue \
          "Based on the analysis, generate the missing documentation files and update existing ones."
      fi
  artifacts:
    paths:
      - doc_analysis.md
      - "*.md"
    expire_in: 1 week
```

### Example 2: Performance Analysis Pipeline
```yaml
performance-analysis:
  stage: quality-gate
  image: node:18
  before_script:
    - npm install -g opencode-ai
    - mkdir -p ~/.config/opencode
    - echo "{\"providers\":{\"anthropic\":{\"apiKey\":\"$ANTHROPIC_API_KEY\"}}}" > ~/.config/opencode/opencode.json
  script:
    - |
      # Get changed files in MR
      if [ "$CI_PIPELINE_SOURCE" = "merge_request_event" ]; then
        CHANGED_FILES=$(git diff --name-only $CI_MERGE_REQUEST_TARGET_BRANCH_SHA $CI_COMMIT_SHA)
      else
        CHANGED_FILES=$(git diff --name-only HEAD~1 HEAD)
      fi
      
      # Performance analysis
      PERF_RESULT=$(opencode run --agent plan \
        "Analyze these files for performance issues and optimization opportunities: $CHANGED_FILES
         
         Focus on:
         - Algorithm complexity
         - Database query optimization  
         - Memory usage patterns
         - Caching opportunities
         - Async/await usage
         - Bundle size impact
         
         Provide a performance score (1-10) and specific recommendations.")
      
      echo "$PERF_RESULT" > performance_analysis.md
      
      # Extract performance score (assuming AI provides it)
      SCORE=$(echo "$PERF_RESULT" | grep -o "Score.*[0-9]" | grep -o "[0-9]" | tail -1)
      
      if [ -n "$SCORE" ] && [ "$SCORE" -lt 7 ]; then
        echo "‚ùå Performance score ($SCORE/10) below threshold (7/10)"
        echo "See performance_analysis.md for details"
        exit 1
      fi
      
      echo "‚úÖ Performance analysis passed (Score: ${SCORE:-N/A}/10)"
  artifacts:
    paths:
      - performance_analysis.md
    expire_in: 1 week
  only:
    - merge_requests
```

## Jenkins Pipeline Examples

### Example 1: Comprehensive Code Quality Pipeline
```groovy
pipeline {
    agent any
    
    environment {
        OPENCODE_DISABLE_AUTOUPDATE = 'true'
        OPENCODE_DISABLE_TERMINAL_TITLE = 'true'
        PATH = "${env.HOME}/.local/bin:${env.PATH}"
    }
    
    stages {
        stage('Setup OpenCode') {
            steps {
                sh '''
                    if ! command -v opencode &> /dev/null; then
                        curl -fsSL https://opencode.ai/install | bash
                    fi
                    
                    mkdir -p ~/.config/opencode
                    echo "{\\"providers\\":{\\"anthropic\\":{\\"apiKey\\":\\"${ANTHROPIC_API_KEY}\\"}}}" > ~/.config/opencode/opencode.json
                '''
            }
        }
        
        stage('Code Analysis') {
            parallel {
                stage('Security Review') {
                    steps {
                        script {
                            def securityResult = sh(
                                script: '''
                                    opencode run --agent plan --title "Security Review" \
                                    "Perform a thorough security analysis of this codebase. Identify vulnerabilities, security anti-patterns, and provide specific remediation steps."
                                ''',
                                returnStdout: true
                            ).trim()
                            
                            writeFile file: 'security-report.md', text: securityResult
                            
                            // Check for critical issues
                            if (securityResult.toLowerCase().contains('critical') || 
                                securityResult.toLowerCase().contains('severe')) {
                                error('Critical security issues found!')
                            }
                        }
                    }
                }
                
                stage('Code Quality') {
                    steps {
                        script {
                            def qualityResult = sh(
                                script: '''
                                    opencode run --agent plan --title "Code Quality Review" \
                                    "Analyze code quality focusing on:
                                     - Code complexity and maintainability
                                     - Design patterns usage
                                     - SOLID principles adherence
                                     - Test coverage gaps
                                     - Technical debt
                                     Provide specific improvement suggestions."
                                ''',
                                returnStdout: true
                            ).trim()
                            
                            writeFile file: 'quality-report.md', text: qualityResult
                        }
                    }
                }
                
                stage('Performance Analysis') {
                    steps {
                        script {
                            def perfResult = sh(
                                script: '''
                                    opencode run --agent plan --title "Performance Analysis" \
                                    "Analyze the codebase for performance bottlenecks and optimization opportunities. Consider memory usage, algorithm efficiency, and scalability."
                                ''',
                                returnStdout: true
                            ).trim()
                            
                            writeFile file: 'performance-report.md', text: perfResult
                        }
                    }
                }
            }
        }
        
        stage('Generate Summary') {
            steps {
                script {
                    def summaryResult = sh(
                        script: '''
                            opencode run --agent general --title "Analysis Summary" \
                            "Create a comprehensive summary report combining the findings from security-report.md, quality-report.md, and performance-report.md. Include priority recommendations and overall assessment." \
                            --file security-report.md --file quality-report.md --file performance-report.md
                        ''',
                        returnStdout: true
                    ).trim()
                    
                    writeFile file: 'analysis-summary.md', text: summaryResult
                }
            }
        }
        
        stage('Auto-Improvement') {
            when {
                anyOf {
                    branch 'develop'
                    branch 'main'
                }
            }
            steps {
                script {
                    sh '''
                        # Create improvement branch
                        git checkout -b "improvement/ai-suggestions-$(date +%s)"
                        
                        # Apply automated improvements
                        opencode run --agent build --title "Auto-Improvements" \
                        "Based on the analysis reports, implement safe, automated improvements such as:
                         - Adding missing documentation
                         - Fixing code style issues
                         - Adding type hints
                         - Optimizing imports
                         - Adding basic tests
                         Only make changes that are clearly beneficial and low-risk."
                        
                        # Commit if changes were made
                        if [ -n "$(git status --porcelain)" ]; then
                            git config --local user.email "jenkins@company.com"
                            git config --local user.name "Jenkins AI"
                            git add .
                            git commit -m "AI Auto-improvements based on code analysis

                            - Applied safe optimizations identified by OpenCode AI
                            - See analysis reports for full details"
                            
                            git push origin HEAD
                            
                            echo "‚úÖ Auto-improvement branch created and pushed"
                        else
                            echo "‚ÑπÔ∏è No automated improvements were applied"
                        fi
                    '''
                }
            }
        }
    }
    
    post {
        always {
            archiveArtifacts artifacts: '*-report.md, analysis-summary.md', 
                            allowEmptyArchive: true
            
            // Publish reports
            publishHTML([
                allowMissing: false,
                alwaysLinkToLastBuild: true,
                keepAll: true,
                reportDir: '.',
                reportFiles: 'analysis-summary.md',
                reportName: 'AI Analysis Summary'
            ])
        }
        
        failure {
            script {
                def failureAnalysis = sh(
                    script: '''
                        opencode run --agent general --title "Build Failure Analysis" \
                        "Analyze this Jenkins build failure and provide specific steps to resolve it. Consider the pipeline configuration, environment setup, and any error messages."
                    ''',
                    returnStdout: true
                ).trim()
                
                writeFile file: 'failure-analysis.md', text: failureAnalysis
                
                emailext subject: 'Build Failed - AI Analysis Available',
                         body: "Build failed. AI Analysis available in artifacts.\n\nQuick Summary:\n${failureAnalysis.take(500)}...",
                         attachmentsPattern: 'failure-analysis.md',
                         to: '${DEFAULT_RECIPIENTS}'
            }
        }
        
        success {
            script {
                if (env.BRANCH_NAME == 'main') {
                    // Update documentation on successful main branch builds
                    sh '''
                        opencode run --agent build --title "Documentation Update" \
                        "Update the project documentation based on any recent changes. Ensure README.md, API docs, and changelog are current."
                    '''
                }
            }
        }
    }
}
```

## Shell Script Patterns

### Pattern 1: Pre-commit Hook with AI Validation
```bash
#!/bin/bash
# .git/hooks/pre-commit

set -e

echo "ü§ñ Running OpenCode pre-commit validation..."

# Get staged files
STAGED_FILES=$(git diff --cached --name-only --diff-filter=ACM)

if [ -z "$STAGED_FILES" ]; then
    echo "No staged files to analyze."
    exit 0
fi

# Quick validation check
VALIDATION_RESULT=$(opencode run --agent plan --format json \
    "Quick pre-commit validation for these staged files: $STAGED_FILES
     
     Check for:
     - Obvious bugs or syntax errors
     - Security vulnerabilities
     - Code style violations
     - Missing error handling
     
     Return PASS or FAIL with brief explanation." | jq -r '.content // .message // .')

echo "Validation Result:"
echo "$VALIDATION_RESULT"

# Check for blocking issues
if echo "$VALIDATION_RESULT" | grep -i "fail\|error\|critical\|blocking"; then
    echo ""
    echo "‚ùå Pre-commit validation failed!"
    echo "Fix the issues above before committing or use --no-verify to skip."
    exit 1
fi

echo "‚úÖ Pre-commit validation passed!"
```

### Pattern 2: Automated Code Review Script
```bash
#!/bin/bash
# code-review.sh

BRANCH=${1:-main}
TARGET=${2:-HEAD}

echo "üîç Starting AI code review for changes from $BRANCH to $TARGET"

# Get diff information
CHANGED_FILES=$(git diff --name-only $BRANCH..$TARGET)
DIFF_STATS=$(git diff --stat $BRANCH..$TARGET)

if [ -z "$CHANGED_FILES" ]; then
    echo "No changes found between $BRANCH and $TARGET"
    exit 0
fi

echo "Changed files: $CHANGED_FILES"
echo "Diff stats: $DIFF_STATS"

# Perform comprehensive review
REVIEW_RESULT=$(opencode run --agent plan --title "Code Review" \
    "Perform a comprehensive code review of the changes between $BRANCH and $TARGET.
     
     Changed files: $CHANGED_FILES
     
     Please analyze:
     1. Code quality and maintainability
     2. Security implications
     3. Performance impact
     4. Testing adequacy
     5. Documentation needs
     6. Potential breaking changes
     
     Provide specific recommendations and highlight any concerns.")

# Save review to file
REVIEW_FILE="code-review-$(date +%Y%m%d-%H%M%S).md"
cat << EOF > "$REVIEW_FILE"
# Code Review Report

**Branch:** $BRANCH ‚Üí $TARGET
**Date:** $(date)
**Changed Files:** $CHANGED_FILES

## Diff Statistics
\`\`\`
$DIFF_STATS
\`\`\`

## AI Review Results
$REVIEW_RESULT

---
*Generated by OpenCode AI*
EOF

echo "üìã Review saved to: $REVIEW_FILE"

# Check for critical issues
if echo "$REVIEW_RESULT" | grep -i "critical\|severe\|blocking\|security.*risk"; then
    echo ""
    echo "‚ö†Ô∏è Critical issues found in review - see $REVIEW_FILE"
    exit 1
fi

echo "‚úÖ Code review completed successfully"
```

### Pattern 3: Intelligent Deployment Validation
```bash
#!/bin/bash
# deployment-validator.sh

ENVIRONMENT=${1:-staging}
CONFIG_DIR=${2:-./config}

echo "üöÄ Validating deployment configuration for $ENVIRONMENT"

# Check if config directory exists
if [ ! -d "$CONFIG_DIR" ]; then
    echo "‚ùå Configuration directory not found: $CONFIG_DIR"
    exit 1
fi

# Pre-deployment validation
VALIDATION_RESULT=$(opencode run --agent plan --title "Deployment Validation" \
    "Validate the deployment configuration for the $ENVIRONMENT environment.
     
     Configuration directory: $CONFIG_DIR
     
     Please check:
     1. Environment-specific configuration files
     2. Security settings and secrets management
     3. Resource limits and scaling parameters
     4. Database migration requirements
     5. Dependency compatibility
     6. Health check configurations
     7. Rollback procedures
     
     Identify any potential deployment risks or misconfigurations.")

echo "Validation Results:"
echo "$VALIDATION_RESULT"

# Check for deployment blockers
if echo "$VALIDATION_RESULT" | grep -i "error\|misconfigur\|incompatib\|missing.*requir"; then
    echo ""
    echo "‚ùå Deployment validation failed!"
    echo "Resolve the issues above before proceeding with deployment."
    exit 1
fi

# Generate deployment checklist
CHECKLIST=$(opencode run --agent general --continue --title "Deployment Checklist" \
    "Based on the validation results, generate a pre-deployment checklist for the $ENVIRONMENT environment.")

echo ""
echo "üìã Deployment Checklist:"
echo "$CHECKLIST"

echo ""
echo "‚úÖ Deployment validation completed successfully!"
```

### Pattern 4: Incident Response Automation
```bash
#!/bin/bash
# incident-response.sh

ALERT_TYPE="$1"
SEVERITY="$2"
DESCRIPTION="$3"
LOG_FILE="$4"

echo "üö® Processing $SEVERITY incident: $ALERT_TYPE"

# Initial incident analysis
TRIAGE_RESULT=$(opencode run --agent general --title "Incident Triage" \
    "Incident triage for $ALERT_TYPE alert with $SEVERITY severity:
     
     Description: $DESCRIPTION
     
     Please provide:
     1. Initial assessment and impact analysis
     2. Immediate containment steps
     3. Investigation priorities
     4. Communication requirements
     5. Escalation recommendations
     
     Focus on actionable next steps.")

echo "üîç Triage Analysis:"
echo "$TRIAGE_RESULT"

# Log analysis if provided
if [ -f "$LOG_FILE" ]; then
    echo ""
    echo "üìã Analyzing logs..."
    
    LOG_ANALYSIS=$(opencode run --agent explore --continue --title "Log Analysis" \
        "Analyze the following log entries in context of the $ALERT_TYPE incident:
         
         Look for error patterns, anomalies, and correlation with the reported issue.
         Provide insights on root cause and recommended actions." \
        --file "$LOG_FILE")
    
    echo "Log Analysis Results:"
    echo "$LOG_ANALYSIS"
fi

# Generate incident report template
INCIDENT_ID="INC-$(date +%Y%m%d-%H%M%S)"
REPORT_FILE="incident-report-$INCIDENT_ID.md"

opencode run --agent build --continue --title "Incident Report Generation" \
    "Generate a structured incident report based on the triage and log analysis.
     
     Include:
     - Incident summary and timeline
     - Impact assessment
     - Investigation findings
     - Actions taken
     - Root cause analysis (if identified)
     - Follow-up items
     - Lessons learned
     
     Save as markdown format." > "$REPORT_FILE"

echo ""
echo "üìÑ Incident report generated: $REPORT_FILE"
echo "üé´ Incident ID: $INCIDENT_ID"

# Auto-create remediation suggestions if possible
if echo "$TRIAGE_RESULT $LOG_ANALYSIS" | grep -i "fix\|solution\|resolve"; then
    echo ""
    echo "üîß Generating remediation suggestions..."
    
    REMEDIATION=$(opencode run --agent build --continue --title "Remediation Plan" \
        "Based on the incident analysis, create specific remediation steps that can be implemented to resolve this issue and prevent recurrence.")
    
    echo "$REMEDIATION" >> "$REPORT_FILE"
    echo ""
    echo "Remediation suggestions added to report."
fi
```

## Docker Integration

### Multi-Stage OpenCode Container
```dockerfile
# Base image with OpenCode
FROM node:18-slim as opencode-base

# Install system dependencies
RUN apt-get update && apt-get install -y \
    curl \
    git \
    jq \
    && rm -rf /var/lib/apt/lists/*

# Install OpenCode
RUN npm install -g opencode-ai

# Configure OpenCode directory
RUN mkdir -p /root/.config/opencode
WORKDIR /workspace

# Development analysis stage
FROM opencode-base as code-analyzer
COPY analyze-code.sh /usr/local/bin/
RUN chmod +x /usr/local/bin/analyze-code.sh
CMD ["analyze-code.sh"]

# Security scanning stage  
FROM opencode-base as security-scanner
COPY security-scan.sh /usr/local/bin/
RUN chmod +x /usr/local/bin/security-scan.sh
CMD ["security-scan.sh"]

# Documentation generator stage
FROM opencode-base as doc-generator
COPY generate-docs.sh /usr/local/bin/
RUN chmod +x /usr/local/bin/generate-docs.sh
CMD ["generate-docs.sh"]

# Production CI/CD stage
FROM opencode-base as ci-runner
COPY ci-scripts/ /ci-scripts/
RUN chmod +x /ci-scripts/*.sh
ENV PATH="/ci-scripts:${PATH}"
CMD ["bash"]
```

### Docker Compose for CI Pipeline
```yaml
version: '3.8'

services:
  opencode-security:
    build:
      context: .
      target: security-scanner
    volumes:
      - .:/workspace:ro
    environment:
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - OPENCODE_DISABLE_AUTOUPDATE=true
    command: security-scan.sh

  opencode-quality:
    build:
      context: .
      target: code-analyzer
    volumes:
      - .:/workspace
    environment:
      - OPENCODE_ZEN_API_KEY=${OPENCODE_ZEN_API_KEY}
      - OPENCODE_DISABLE_TERMINAL_TITLE=true
    command: analyze-code.sh

  opencode-docs:
    build:
      context: .
      target: doc-generator
    volumes:
      - .:/workspace
      - ./docs:/output
    environment:
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
    command: generate-docs.sh

  opencode-integration:
    build:
      context: .
      target: ci-runner
    volumes:
      - .:/workspace
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - OPENCODE_ZEN_API_KEY=${OPENCODE_ZEN_API_KEY}
      - GITHUB_TOKEN=${GITHUB_TOKEN}
    depends_on:
      - opencode-security
      - opencode-quality
      - opencode-docs
```

## Error Handling & Logging

### Robust OpenCode Wrapper Script
```bash
#!/bin/bash
# robust-opencode-wrapper.sh

set -euo pipefail

# Configuration
MAX_RETRIES=3
RETRY_DELAY=5
LOG_FILE="${OPENCODE_LOG_FILE:-/tmp/opencode-ci.log}"
DEFAULT_AGENT="${OPENCODE_DEFAULT_AGENT:-general}"

# Logging functions
log_info() {
    echo "$(date '+%Y-%m-%d %H:%M:%S') [INFO] $1" | tee -a "$LOG_FILE"
}

log_error() {
    echo "$(date '+%Y-%m-%d %H:%M:%S') [ERROR] $1" | tee -a "$LOG_FILE" >&2
}

log_success() {
    echo "$(date '+%Y-%m-%d %H:%M:%S') [SUCCESS] $1" | tee -a "$LOG_FILE"
}

# Retry function with exponential backoff
retry_opencode_command() {
    local agent="$1"
    local prompt="$2"
    local title="${3:-}"
    local attempt=1
    local delay=$RETRY_DELAY
    
    while [ $attempt -le $MAX_RETRIES ]; do
        log_info "Attempting OpenCode command (attempt $attempt/$MAX_RETRIES)"
        
        local cmd="opencode run --agent $agent"
        if [ -n "$title" ]; then
            cmd="$cmd --title \"$title\""
        fi
        cmd="$cmd \"$prompt\""
        
        if result=$(eval "$cmd" 2>&1); then
            log_success "Command succeeded on attempt $attempt"
            echo "$result"
            return 0
        else
            log_error "Attempt $attempt failed: $result"
            
            if [ $attempt -eq $MAX_RETRIES ]; then
                log_error "All retry attempts failed"
                return 1
            fi
            
            log_info "Waiting $delay seconds before retry..."
            sleep $delay
            delay=$((delay * 2))  # Exponential backoff
            ((attempt++))
        fi
    done
}

# Input sanitization
sanitize_prompt() {
    local prompt="$1"
    # Remove potential sensitive data patterns and control characters
    echo "$prompt" | \
        sed 's/password=[^[:space:]]*/password=****/gi' | \
        sed 's/api[_-]key=[^[:space:]]*/api_key=****/gi' | \
        sed 's/token=[^[:space:]]*/token=****/gi' | \
        tr -d '\000-\010\013\014\016-\037'
}

# Validate environment
validate_environment() {
    # Check if OpenCode is installed
    if ! command -v opencode &> /dev/null; then
        log_error "OpenCode not found. Please install it first."
        return 1
    fi
    
    # Check if configuration exists
    if [ ! -f "$HOME/.config/opencode/opencode.json" ] && [ -z "${ANTHROPIC_API_KEY:-}${OPENAI_API_KEY:-}${OPENCODE_ZEN_API_KEY:-}" ]; then
        log_error "No OpenCode configuration or API keys found."
        return 1
    fi
    
    # Test basic connectivity
    if ! opencode run --agent plan "test" >/dev/null 2>&1; then
        log_error "OpenCode connectivity test failed."
        return 1
    fi
    
    return 0
}

# Main execution function
main() {
    local agent="${1:-$DEFAULT_AGENT}"
    local prompt="$2"
    local title="${3:-}"
    
    log_info "Starting OpenCode wrapper"
    log_info "Agent: $agent, Prompt length: ${#prompt} characters"
    
    # Validate environment
    if ! validate_environment; then
        exit 1
    fi
    
    # Sanitize the prompt
    local sanitized_prompt
    sanitized_prompt=$(sanitize_prompt "$prompt")
    
    # Validate prompt length (OpenCode has context limits)
    if [ ${#sanitized_prompt} -gt 50000 ]; then
        log_error "Prompt too long (${#sanitized_prompt} characters, max 50000)"
        exit 1
    fi
    
    # Execute with retry logic
    if retry_opencode_command "$agent" "$sanitized_prompt" "$title"; then
        log_success "Operation completed successfully"
        exit 0
    else
        log_error "Operation failed after all retries"
        exit 1
    fi
}

# Help function
show_help() {
    cat << EOF
Usage: $0 [AGENT] <PROMPT> [TITLE]

Arguments:
  AGENT     OpenCode agent to use (default: $DEFAULT_AGENT)
  PROMPT    The prompt to send to OpenCode (required)
  TITLE     Optional session title

Environment Variables:
  OPENCODE_DEFAULT_AGENT   Default agent to use
  OPENCODE_LOG_FILE       Log file path (default: /tmp/opencode-ci.log)
  MAX_RETRIES            Maximum retry attempts (default: 3)
  RETRY_DELAY            Initial retry delay in seconds (default: 5)

Examples:
  $0 plan "Review this code for security issues"
  $0 build "Implement user authentication" "Auth Feature"
  $0 explore "Find all API endpoints in the codebase"
EOF
}

# Parse arguments
if [ $# -eq 0 ] || [ "$1" = "--help" ] || [ "$1" = "-h" ]; then
    show_help
    exit 0
fi

if [ $# -eq 1 ]; then
    # Only prompt provided, use default agent
    main "$DEFAULT_AGENT" "$1"
elif [ $# -eq 2 ]; then
    # Agent and prompt provided
    main "$1" "$2"
elif [ $# -eq 3 ]; then
    # Agent, prompt, and title provided
    main "$1" "$2" "$3"
else
    log_error "Too many arguments provided"
    show_help
    exit 1
fi
```

### Structured JSON Logging
```bash
#!/bin/bash
# structured-opencode-logger.sh

# JSON logging function
json_log() {
    local level="$1"
    local message="$2"
    local extra="${3:-{}}"
    local session_id="${4:-}"
    
    jq -n \
        --arg timestamp "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
        --arg level "$level" \
        --arg message "$message" \
        --arg session_id "$session_id" \
        --argjson extra "$extra" \
        '{
            timestamp: $timestamp,
            level: $level,
            message: $message,
            service: "opencode-ci",
            session_id: $session_id,
            extra: $extra
        }'
}

# Execute OpenCode with comprehensive logging
execute_with_logging() {
    local agent="$1"
    local prompt="$2"
    local title="${3:-}"
    local start_time=$(date +%s.%N)
    local session_id=$(uuidgen 2>/dev/null || date +%s)
    
    # Log start
    json_log "INFO" "Starting OpenCode execution" "{
        \"agent\": \"$agent\",
        \"prompt_length\": ${#prompt},
        \"title\": \"$title\"
    }" "$session_id"
    
    # Build command
    local cmd="opencode run --agent $agent --format json"
    if [ -n "$title" ]; then
        cmd="$cmd --title \"$title\""
    fi
    cmd="$cmd \"$prompt\""
    
    # Execute and capture output
    local exit_code=0
    local result
    result=$(eval "$cmd" 2>&1) || exit_code=$?
    
    local end_time=$(date +%s.%N)
    local duration=$(echo "$end_time - $start_time" | bc -l)
    
    if [ $exit_code -eq 0 ]; then
        # Parse OpenCode JSON response if possible
        local content_length=0
        local tokens_used="null"
        local model_used="null"
        
        if echo "$result" | jq . >/dev/null 2>&1; then
            content_length=$(echo "$result" | jq -r '.content // .message // ""' | wc -c)
            tokens_used=$(echo "$result" | jq -r '.usage.total_tokens // null')
            model_used=$(echo "$result" | jq -r '.model // null')
        else
            content_length=${#result}
        fi
        
        json_log "SUCCESS" "Command completed successfully" "{
            \"duration_seconds\": $duration,
            \"result_length\": $content_length,
            \"tokens_used\": $tokens_used,
            \"model_used\": \"$model_used\",
            \"exit_code\": $exit_code
        }" "$session_id"
        
        echo "$result"
        return 0
    else
        json_log "ERROR" "Command failed" "{
            \"duration_seconds\": $duration,
            \"exit_code\": $exit_code,
            \"error\": \"$result\"
        }" "$session_id"
        
        return $exit_code
    fi
}

# Usage validation
if [ $# -lt 2 ]; then
    json_log "ERROR" "Insufficient arguments provided" "{\"args_count\": $#}"
    echo "Usage: $0 <agent> <prompt> [title]" >&2
    exit 1
fi

# Check dependencies
if ! command -v jq >/dev/null 2>&1; then
    echo "Error: jq is required for JSON logging" >&2
    exit 1
fi

if ! command -v bc >/dev/null 2>&1; then
    echo "Warning: bc not found, duration calculation may be imprecise" >&2
fi

# Execute with structured logging
execute_with_logging "$1" "$2" "${3:-}"
```

## Best Practices

### 1. Agent Selection Best Practices
```bash
# ‚úÖ Good - Use appropriate agents for tasks
opencode run --agent plan "Analyze security vulnerabilities"     # Read-only analysis
opencode run --agent build "Implement the login feature"         # Full implementation  
opencode run --agent explore "Find all API endpoints"            # Fast codebase exploration

# ‚ùå Avoid - Using wrong agent for task
opencode run --agent build "Analyze this code"                   # Overkill, use plan
opencode run --agent plan "Create new files"                     # Won't work, use build
```

### 2. Prompt Engineering Best Practices
```bash
# ‚úÖ Good - Specific, actionable prompts
opencode run --agent plan --title "Security Review" \
    "Review the authentication module in src/auth/ for:
     1. SQL injection vulnerabilities
     2. JWT token validation
     3. Password hashing security
     4. Session management issues
     Provide specific line numbers and fix recommendations."

# ‚ùå Avoid - Vague prompts
opencode run --agent plan "Check security"

# ‚úÖ Good - Structured requests with context
opencode run --agent build --title "User API Implementation" \
    "Implement a REST API for user management with:
     - GET /users (list with pagination)
     - POST /users (create new user)
     - PUT /users/:id (update existing)
     - DELETE /users/:id (soft delete)
     
     Use Express.js, follow existing patterns in src/api/,
     include input validation and error handling."

# ‚ùå Avoid - Overly complex single requests  
opencode run --agent build "Build entire user system with auth, API, frontend, tests, docs"
```

### 3. Session Management Best Practices
```bash
# ‚úÖ Good - Use descriptive titles for tracking
opencode run --agent plan --title "Security Audit - $(date +%Y%m%d)" \
    "Perform security audit of payment processing module"

# ‚úÖ Good - Continue related work in same session
opencode run --agent build --continue --title "Payment Module Implementation" \
    "Now implement the secure payment processing based on the previous audit findings"

# ‚úÖ Good - Clean up old sessions periodically
cleanup_opencode_sessions() {
    # Get session list and clean up old ones
    opencode session list --format json | \
    jq -r '.sessions[] | select(.lastActivity < (now - 86400*7)) | .id' | \
    while read session_id; do
        echo "Cleaning up old session: $session_id"
        # Note: Actual cleanup command may vary
    done
}

# ‚ùå Avoid - Creating too many disconnected sessions
opencode run --agent build "Small fix 1"
opencode run --agent build "Small fix 2"  # Should continue previous session
```

### 4. Error Recovery Patterns
```bash
# Progressive capability fallback
analyze_with_fallback() {
    local files="$1"
    local prompt="$2"
    
    # Try with full build agent first
    if result=$(opencode run --agent build --title "Full Analysis" "$prompt" 2>/dev/null); then
        echo "$result"
        return 0
    fi
    
    # Fallback to plan agent (read-only)
    if result=$(opencode run --agent plan --title "Analysis Only" "$prompt" 2>/dev/null); then
        echo "READ-ONLY ANALYSIS: $result"
        return 0
    fi
    
    # Final fallback to general agent
    if result=$(opencode run --agent general --title "General Analysis" \
        "Provide general guidance for: $prompt" 2>/dev/null); then
        echo "GENERAL GUIDANCE: $result"
        return 0
    fi
    
    echo "ANALYSIS UNAVAILABLE: All agents failed for prompt: $prompt"
    return 1
}

# Graceful degradation for file operations
safe_file_analysis() {
    local file_pattern="$1"
    
    # Try to analyze specific files first
    if result=$(opencode run --agent explore --file "$file_pattern" \
        "Analyze these specific files" 2>/dev/null); then
        echo "$result"
    else
        # Fallback to pattern-based analysis
        opencode run --agent explore \
            "Analyze files matching pattern: $file_pattern (without direct file access)"
    fi
}
```

### 5. Performance Optimization
```bash
# ‚úÖ Good - Batch related operations
opencode run --agent plan --title "Complete Security Review" \
    "Perform comprehensive security analysis of:
     1. Authentication system (src/auth/)
     2. API endpoints (src/api/)  
     3. Database queries (src/models/)
     4. Configuration files (config/)
     Provide consolidated report with prioritized findings."

# ‚ùå Avoid - Multiple separate calls for related tasks
opencode run --agent plan "Check auth security"
opencode run --agent plan "Check API security"  
opencode run --agent plan "Check database security"
opencode run --agent plan "Check config security"

# ‚úÖ Good - Use file attachments efficiently
opencode run --agent plan --title "Multi-file Review" \
    "Review these configuration files for security issues" \
    --file config/database.yml \
    --file config/app.yml \
    --file docker-compose.yml

# ‚úÖ Good - Cache results for expensive operations
cache_expensive_analysis() {
    local cache_key=$(echo "$*" | md5sum | cut -d' ' -f1)
    local cache_file="/tmp/opencode-cache-$cache_key"
    
    if [ -f "$cache_file" ] && [ "$(find "$cache_file" -mmin -60)" ]; then
        echo "Using cached result..."
        cat "$cache_file"
    else
        echo "Running fresh analysis..."
        opencode run --agent plan "$@" | tee "$cache_file"
    fi
}
```

## Troubleshooting

### Common Issues and Solutions

#### Issue 1: Agent Not Found
```bash
# Problem: Invalid agent name causes warnings
# Solution: Validate agent names and provide fallbacks

validate_agent() {
    local agent="$1"
    local available_agents
    available_agents=$(opencode agent list | grep -E '^\w+' | awk '{print $1}')
    
    if echo "$available_agents" | grep -q "^$agent\$"; then
        return 0
    else
        echo "Warning: Agent '$agent' not found. Available agents:"
        echo "$available_agents"
        echo "Using 'general' agent as fallback."
        return 1
    fi
}

# Usage
AGENT="myagent"
if ! validate_agent "$AGENT"; then
    AGENT="general"
fi
opencode run --agent "$AGENT" "Your prompt here"
```

#### Issue 2: Context Window Limits
```bash
# Handle large codebases by chunking analysis
analyze_large_codebase() {
    local base_prompt="$1"
    local file_list="$2"
    local chunk_size=10
    
    echo "$file_list" | split -l $chunk_size - chunk_
    
    for chunk_file in chunk_*; do
        local files=$(cat "$chunk_file" | tr '\n' ' ')
        echo "Analyzing chunk: $files"
        
        opencode run --agent plan \
            "Analyze these files as part of a larger codebase review: $base_prompt
             Files in this chunk: $files"
        
        rm "$chunk_file"
    done
}

# Usage
FILE_LIST=$(find src/ -name "*.js" -o -name "*.ts")
analyze_large_codebase "Security review focusing on authentication" "$FILE_LIST"
```

#### Issue 3: Session State Management
```bash
# Manage session state effectively
manage_session_state() {
    local operation="$1"
    local session_file="/tmp/opencode_session.txt"
    
    case "$operation" in
        "start")
            # Start new session and save ID
            SESSION_OUTPUT=$(opencode run --agent plan --title "New Analysis Session" \
                "Starting new analysis session" --format json)
            echo "$SESSION_OUTPUT" | jq -r '.session_id // empty' > "$session_file"
            ;;
        "continue")
            # Continue existing session if available
            if [ -f "$session_file" ]; then
                local session_id=$(cat "$session_file")
                opencode run --session "$session_id" --agent build --continue "$2"
            else
                echo "No existing session found, starting new one"
                manage_session_state "start"
            fi
            ;;
        "cleanup")
            # Clean up session file
            rm -f "$session_file"
            ;;
    esac
}

# Usage
manage_session_state "start"
manage_session_state "continue" "Implement the planned changes"
manage_session_state "cleanup"
```

#### Issue 4: Rate Limiting and Costs
```bash
# Implement rate limiting and cost control
check_usage_limits() {
    # This would need to be adapted based on actual OpenCode usage reporting
    local usage_info
    usage_info=$(opencode stats --format json 2>/dev/null || echo '{}')
    
    local daily_requests
    daily_requests=$(echo "$usage_info" | jq -r '.daily_requests // 0')
    
    if [ "$daily_requests" -gt 1000 ]; then
        echo "Warning: High usage detected ($daily_requests requests today)"
        echo "Consider using plan agent for analysis-only tasks"
        return 1
    fi
    return 0
}

# Smart agent selection based on usage
smart_agent_selection() {
    local task_type="$1"
    local prompt="$2"
    
    if ! check_usage_limits; then
        echo "Using lighter analysis due to usage limits"
        case "$task_type" in
            "analysis"|"review")
                opencode run --agent plan "$prompt"
                ;;
            "implementation")
                echo "Skipping implementation due to usage limits. Analysis only:"
                opencode run --agent plan "Analyze requirements for: $prompt"
                ;;
            *)
                opencode run --agent explore "$prompt"
                ;;
        esac
    else
        # Normal operation
        case "$task_type" in
            "analysis"|"review")
                opencode run --agent plan "$prompt"
                ;;
            "implementation")
                opencode run --agent build "$prompt"
                ;;
            *)
                opencode run --agent general "$prompt"
                ;;
        esac
    fi
}
```

#### Issue 5: Network and Connectivity Issues
```bash
# Network resilience and offline fallback
check_opencode_connectivity() {
    local test_prompt="test connectivity"
    
    if timeout 30 opencode run --agent plan "$test_prompt" >/dev/null 2>&1; then
        return 0
    else
        echo "OpenCode connectivity test failed"
        return 1
    fi
}

# Offline fallback strategies
run_with_fallback() {
    local prompt="$1"
    local fallback_action="$2"
    
    if check_opencode_connectivity; then
        opencode run --agent general "$prompt"
    else
        echo "OpenCode unavailable. Running fallback: $fallback_action"
        case "$fallback_action" in
            "static_analysis")
                # Run static analysis tools as fallback
                find . -name "*.js" -exec eslint {} \; 2>/dev/null || echo "No static analysis available"
                ;;
            "template_response")
                echo "OFFLINE MODE: Cannot analyze '$prompt'. Please check connectivity and retry."
                ;;
            "cache_lookup")
                # Look for cached responses
                local cache_key=$(echo "$prompt" | md5sum | cut -d' ' -f1)
                local cache_file="/tmp/opencode-offline-cache-$cache_key"
                if [ -f "$cache_file" ]; then
                    echo "Using cached response:"
                    cat "$cache_file"
                else
                    echo "No cached response available for this query."
                fi
                ;;
        esac
    fi
}
```

### Debugging Techniques

#### Enable Verbose Output
```bash
# Debug OpenCode operations
debug_opencode() {
    local agent="$1"
    local prompt="$2"
    
    echo "Debug: Agent=$agent, Prompt length=${#prompt}"
    
    # Set debug environment variables if available
    export OPENCODE_LOG_LEVEL=debug
    export OPENCODE_PRINT_LOGS=true
    
    # Run with JSON format for structured output
    local result
    result=$(opencode run --agent "$agent" --format json "$prompt" 2>&1)
    
    local exit_code=$?
    
    echo "Debug: Exit code=$exit_code"
    echo "Debug: Output length=${#result}"
    
    # Try to parse JSON output
    if echo "$result" | jq . >/dev/null 2>&1; then
        echo "Debug: Valid JSON response received"
        echo "$result" | jq .
    else
        echo "Debug: Non-JSON response received"
        echo "$result"
    fi
    
    return $exit_code
}

# Usage
debug_opencode "plan" "Analyze this error message"
```

#### Performance Monitoring
```bash
# Monitor OpenCode performance
monitor_opencode_performance() {
    local agent="$1"
    local prompt="$2"
    local start_time end_time duration
    
    echo "Starting performance monitoring..."
    start_time=$(date +%s.%N)
    
    # Monitor system resources during execution
    (
        while kill -0 $$ 2>/dev/null; do
            echo "$(date): CPU: $(top -bn1 | grep "Cpu(s)" | awk '{print $2}') Memory: $(free -h | awk 'NR==2{print $3}')"
            sleep 5
        done
    ) &
    local monitor_pid=$!
    
    # Execute OpenCode command
    local result exit_code
    result=$(opencode run --agent "$agent" "$prompt" 2>&1)
    exit_code=$?
    
    # Stop monitoring
    kill $monitor_pid 2>/dev/null || true
    
    end_time=$(date +%s.%N)
    duration=$(echo "$end_time - $start_time" | bc -l)
    
    echo "Performance Results:"
    echo "  Duration: ${duration}s"
    echo "  Exit Code: $exit_code"
    echo "  Output Length: ${#result} characters"
    echo "  Agent Used: $agent"
    echo "  Prompt Length: ${#prompt} characters"
    
    return $exit_code
}
```

This comprehensive guide provides everything needed to successfully integrate OpenCode into CI/CD pipelines across different platforms and use cases. The key is to choose the right agent for each task, handle errors gracefully, and implement proper logging and monitoring for production use.